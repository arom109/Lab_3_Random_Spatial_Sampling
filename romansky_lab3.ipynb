{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona as fi\n",
    "import glob\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1\n",
    "\n",
    "shed_files = fi.listlayers(r'C:\\Users\\arom\\Documents\\School\\Grad School\\Fall 2020\\Automation\\week4\\lab3.gpkg')\n",
    "sheds = []\n",
    "for files in shed_files:\n",
    "    if \"wdbhuc\" in files:\n",
    "        sheds.append(files)\n",
    "\n",
    "#create empty dictionary to append generated points     \n",
    "sample_points = {'point_id': [], 'geometry':[], 'HUC': []}\n",
    "for polys in sheds:\n",
    "    shed_files_gdf = gpd.read_file(r'C:\\Users\\arom\\Documents\\School\\Grad School\\Fall 2020\\Automation\\week4\\lab3.gpkg', layer = polys)\n",
    "    huccode = [f for f in shed_files_gdf.columns if 'HUC' in f][0]\n",
    "    for idx, row in shed_files_gdf.iterrows():\n",
    "        j = 0\n",
    "        #get extents of each polygon, convert to square kilometers, calculate number of points, n\n",
    "        extent = row['geometry'].bounds\n",
    "        area_km = row[\"Shape_Area\"]/1000000\n",
    "        n = (int(round(area_km*0.05)))\n",
    "        #generate random points within our extents\n",
    "        while j < n:\n",
    "            x = random.uniform(extent[0], extent[2])\n",
    "            y = random.uniform(extent[1], extent[3])\n",
    "            p = (Point(x,y))\n",
    "            #if the random point generated is within the polygon, append it to the empty dictionary\n",
    "            if row['geometry'].contains(p):\n",
    "                sample_points['geometry'].append(p)\n",
    "                sample_points['point_id'].append(row[huccode][:8])\n",
    "                sample_points['HUC'].append(huccode)\n",
    "                j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUC    point_id\n",
      "HUC12  10190005    10.841360\n",
      "       10190006    10.492456\n",
      "       10190007    10.623682\n",
      "HUC8   10190005    11.473190\n",
      "       10190006     7.877788\n",
      "       10190007    11.386864\n",
      "Name: aws0150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Part 2\n",
    "\n",
    "#create geodataframe, perform join, group and get average, print\n",
    "sample_points_gdf = gpd.GeoDataFrame(sample_points)\n",
    "ssurgo = gpd.read_file(r'C:\\Users\\arom\\Documents\\School\\Grad School\\Fall 2020\\Automation\\week4\\lab3.gpkg', layer = 'ssurgo_mapunits_lab3')\n",
    "sample_points_gdf = sample_points_gdf.set_crs(\"EPSG:26913\")\n",
    "new_class = gpd.sjoin(sample_points_gdf, ssurgo,  how='left', op=\"within\")\n",
    "\n",
    "group = new_class.groupby(by=['HUC', 'point_id']).mean()\n",
    "print(group['aws0150'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
